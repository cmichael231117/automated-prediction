{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4293\n",
       "1.0     707\n",
       "Name: churned, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = os.sep.join(data_path + ['Orange_Telecom_Churn_Data.csv'])\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "#상관없어보이는 특징 제거\n",
    "data.drop(['account_length','state', 'area_code', 'phone_number', 'total_day_calls'], axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "for col in ['intl_plan', 'voice_mail_plan', 'churned']:\n",
    "    data[col] = lb.fit_transform(data[col])\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "msc = MinMaxScaler()\n",
    "\n",
    "data = pd.DataFrame(msc.fit_transform(data),  # this is an np.array, not a dataframe.\n",
    "                    columns=data.columns)\n",
    "data.churned.value_counts()\n",
    "\n",
    "#data.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_eve_charge,, total_intl_minutes,total_night_minutes, number_vmail_messages, total_day_minutes, total_day_charge, total_eve_minutes, total_eve_calls, total_night_calls, total_night_charge, total_intl_charge, \n",
    "#total_day_calls,\n",
    "#total_intl_calls, number_customer_service_calls 매우 중요한 요소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "churned_indices = data[data.churned == 0.0].index\n",
    "non_churned_indices = data[data.churned == 1.0].index\n",
    "\n",
    "churned_sample = data.loc[churned_indices]\n",
    "shuffled_sample = churned_sample.reindex(np.random.permutation(churned_sample.index))\n",
    "non_churned_sample = data.loc[non_churned_indices]\n",
    "\n",
    "####\n",
    "shuffled_sample2 = non_churned_sample.reindex(np.random.permutation(non_churned_sample.index))\n",
    "#s7 = shuffled_sample2[607:707]\n",
    "#s6 = shuffled_sample[3536:4293]\n",
    "#s7 = pd.concat([s7, s6])\n",
    "####\n",
    "\n",
    "f1 = shuffled_sample2[:606]\n",
    "\n",
    "s1 = shuffled_sample[:707]\n",
    "s1 = pd.concat([s1, f1])\n",
    "s2 = shuffled_sample[708:1414]\n",
    "s2 = pd.concat([s2, f1])\n",
    "s3 = shuffled_sample[1415:2121]\n",
    "s3 = pd.concat([s3, f1])\n",
    "s4 = shuffled_sample[2122:2828]\n",
    "s4 = pd.concat([s4, f1])\n",
    "s5 = shuffled_sample[2829:3535]\n",
    "s5 = pd.concat([s5, f1])\n",
    "\n",
    "f2 = shuffled_sample2[607:707]\n",
    "s6 = shuffled_sample[3536:4293]\n",
    "s6 = pd.concat([s6, f2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [x for x in data.columns if x != 'churned']\n",
    "\n",
    "X_data = data[x_cols]\n",
    "y_data = data['churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [x for x in s1.columns if x != 'churned']\n",
    "X_data_1 = s1[x_cols]\n",
    "y_data_1 = s1['churned']\n",
    "\n",
    "x_cols = [x for x in s2.columns if x != 'churned']\n",
    "X_data_2 = s2[x_cols]\n",
    "y_data_2 = s2['churned']\n",
    "\n",
    "x_cols = [x for x in s3.columns if x != 'churned']\n",
    "X_data_3 = s3[x_cols]\n",
    "y_data_3 = s3['churned']\n",
    "\n",
    "x_cols = [x for x in s4.columns if x != 'churned']\n",
    "X_data_4 = s4[x_cols]\n",
    "y_data_4 = s4['churned']\n",
    "\n",
    "x_cols = [x for x in s5.columns if x != 'churned']\n",
    "X_data_5 = s5[x_cols]\n",
    "y_data_5 = s5['churned']\n",
    "\n",
    "x_cols = [x for x in s6.columns if x != 'churned']\n",
    "X_data_6 = s6[x_cols]\n",
    "y_data_6 = s6['churned']\n",
    "\n",
    "x_cols = [x for x in data.columns if x != 'churned']\n",
    "X_data = data[x_cols]\n",
    "y_data = data['churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "knn4 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "knn5 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "#knn6 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "knn1 = knn1.fit(X_data_1, y_data_1)\n",
    "knn2 = knn2.fit(X_data_2, y_data_2)\n",
    "knn3 = knn3.fit(X_data_3, y_data_3)\n",
    "knn4 = knn4.fit(X_data_4, y_data_4)\n",
    "knn5 = knn5.fit(X_data_5, y_data_5)\n",
    "#knn6 = knn6.fit(X_data_6, y_data_6)\n",
    "\n",
    "y_pred1 = knn1.predict(X_data_6)\n",
    "y_pred2 = knn2.predict(X_data_6)\n",
    "y_pred3 = knn3.predict(X_data_6)\n",
    "y_pred4 = knn4.predict(X_data_6)\n",
    "y_pred5 = knn5.predict(X_data_6)\n",
    "#y_pred6 = knn6.predict(X_data)\n",
    "\n",
    "y_pred = y_pred1 + y_pred2 + y_pred3 + y_pred4 + y_pred5\n",
    "\n",
    "#for i in y_pred:\n",
    "#    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.nditer(y_pred, op_flags=['readwrite']) as it:\n",
    "    for i in it:\n",
    "        if i>=5:\n",
    "            i[...]=1\n",
    "        else:\n",
    "            i[...]=0.0\n",
    "        \n",
    "#for i in y_pred:\n",
    "#    print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[714,  43],\n",
       "       [ 45,  55]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_data_6, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.896431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.897316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fscore</td>\n",
       "      <td>0.896865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.897316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "precision  0.896431\n",
       "recall     0.897316\n",
       "fscore     0.896865\n",
       "accuracy   0.897316"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "metrics = list()\n",
    "\n",
    "precision, recall, fscore, _ = score(y_data_6, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_data_6, y_pred)\n",
    "\n",
    "metrics.append(pd.Series({'precision':precision, 'recall':recall, \n",
    "                        'fscore':fscore, 'accuracy':accuracy}, \n",
    "                        name='scores'))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)\n",
    "\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
